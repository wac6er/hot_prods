{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16fNQTpIKeTl"
      },
      "source": [
        "**Notes:** Press run, enter your preferred amazon product, and then enter your preffered # of topics: \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PRODUCT SEARCH (BRAND V BRAND / SPECIFIC PRODUCTS)\n",
        "\n",
        "#import packages \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import requests \n",
        "import time \n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import re\n",
        "\n",
        "\n",
        "#shared link: https://colab.research.google.com/drive/1LJoBqfg7phAfMmFsTX_-Ng0MPczdP7VS?usp=sharing\n",
        "\n",
        "#set default\n",
        "session_idd = '132-9175929-1227644'\n",
        "tolkienn = 'gu6C9Yb70yHFXqCH2WhWeN4FaxjPCSK2ssod1fdqA0qmbDD/t7wjoA4EDgjPltkuzMfmYq+vquNLrS+kkXbVwcxpGbATWbY3jjctT8v2UUkCTham6oWMn0wwK0cm6LYvWFJpclM/K/XbAioFjW6Dd7OhZPVrTxN+aoKUBIvb2y1jAQiN1lmxcANxia/tnOUw'\n",
        "\n",
        "\n",
        "print('run in default mode (yes/no)')\n",
        "default = input().lower()\n",
        "if default == 'yes':\n",
        "  session_id = session_idd\n",
        "  tolkien = tolkienn\n",
        "  print('run data collection? (yes/no)')\n",
        "  data_collection = input().lower()\n",
        "  print('run topic model? (yes/no)')\n",
        "  topicc_model = input().lower()\n",
        "  print('enter your level (1-10)')\n",
        "  print('HIGH GPU FOR LABELS>3')\n",
        "  level =int(input())\n",
        "  print('enter sleep time, .1s reccommended (3s for levels>10)')\n",
        "  sleep_time = float(input())\n",
        "  print('enter your preferred # of topics for the topic model:')\n",
        "  xcv = int(input())\n",
        "  print('how many products would you like to analyze?')\n",
        "  num_its = int(input())\n",
        "  print('would you like to analyze positive or negative reviews? (positive/negative)')\n",
        "  positiveOrNegative = input().lower()\n",
        "  print('min positive sentiment or max negative sentiment you would like to analyze, depending on the answer to your question above')\n",
        "  print('-1 to 1, .2/-.2 reccomended, the more extreme the parameters the higher your level should be!')\n",
        "  higher_we_go = float(input())\n",
        "\n",
        "else:\n",
        "  print('enter your token (paste)')\n",
        "  tolkien = input()\n",
        "  print('enter your session id')\n",
        "  session_id = input()\n",
        "  print('run data collection? (yes/no)')\n",
        "  data_collection = input().lower()\n",
        "  print('run topic model? (yes/no)')\n",
        "  topicc_model = input().lower()\n",
        "  print('enter your level (1-10)')\n",
        "  level = int(input())\n",
        "  print('enter sleep time, .1s reccommended (3s for levels>10)')\n",
        "  sleep_time = float(input())\n",
        "  print('enter your preferred # of topics for the topic model:')\n",
        "  xcv = int(input())\n",
        "\n",
        "its = {'its':[]}\n",
        "print('enter the product type / brand reviews you would like to analyze')\n",
        "for x in range(num_its):\n",
        "  its['its'].append(str(input()))\n",
        "\n",
        "its = pd.DataFrame(its)\n",
        "\n",
        "\n",
        "for xe in range(len(its)):\n",
        "  saver = {'review':[],'title':[],'verified':[],'text':[]}\n",
        "  uu = {'text':[]}\n",
        "  ccc = {'text':[]}\n",
        "  cc = {'text':[]}\n",
        "  saverr = {'links':[]}\n",
        "  cust_rev = {'id':[],'name':[],'link':[]}\n",
        "  reviews = {'name':[],'id':[]}\n",
        "\n",
        "  if data_collection =='yes':\n",
        "    level = level*3\n",
        "    \n",
        "    for xzx in range(1):\n",
        "      url = 'https://www.amazon.com/s?k='+str(its['its'][xe])+':&page='+str(xzx)\n",
        "      headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36'}\n",
        "      cookies = {'session-id':session_id,'session-id-time':'2082787201l','i18n-prefs':'USD','csm-hit':'tb:s-1KBXPV9W0G7AT013EMW9|1648478470844&t:1648478472672&adb:adblk_no','ubid-main':'132-0411939-8328406','session-token':tolkien}\n",
        "      html = requests.get(url,headers = headers, cookies =cookies).text\n",
        "      soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "      time.sleep(sleep_time)\n",
        "      \n",
        "      for tag in soup.findAll(\"div\", {\"class\": \"s-main-slot s-result-list s-search-results sg-row\"}):\n",
        "        xxxx = tag.findAll(\"a\",{\"class\":\"a-link-normal\"})\n",
        "        if len(xxxx)>=1:\n",
        "          saverr['links'].append(xxxx)\n",
        "        else:\n",
        "          print(xxxx)\n",
        "      print('length of product pages collected: '+str(len(saverr['links'])))\n",
        "    from numpy.ma.core import exp\n",
        "    for xc in range(len(str(saverr['links'][0]).split('\" href=\"/'))):\n",
        "      try:\n",
        "        cust_rev['id'].append(str(saverr['links'][0]).split(';url=%2F')[xc].split('%2F')[2])\n",
        "        cust_rev['name'].append(str(saverr['links'][0]).split(';url=%2F')[xc].split('%2F')[0])\n",
        "      except:\n",
        "        cvc = 2\n",
        "\n",
        "    reviews = pd.DataFrame()\n",
        "    reviews['id'] = pd.DataFrame(cust_rev['id']).drop_duplicates()\n",
        "    reviews['name'] = pd.DataFrame(cust_rev['name']).drop_duplicates()\n",
        "    reviews['link'] = pd.DataFrame(cust_rev['name']).drop_duplicates()\n",
        "    reviews = reviews.reset_index().drop(columns = 'index')\n",
        "\n",
        "    for xi in range(len(reviews)):\n",
        "        reviews['link'].iloc[xi] = 'https://www.amazon.com/'+str(reviews['name'][xi])+'/product-reviews/'+str(reviews['id'][xi])+'/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'\n",
        "\n",
        "    for xv in range(1):#len(reviews['link'])):\n",
        "      for xvv in range(level*5):\n",
        "          xvv = xvv+1\n",
        "          html = requests.get(str(reviews['link'][xv])+'=all_reviews&pageNumber='+str(xvv),headers = headers, cookies =cookies).text\n",
        "          soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "          time.sleep(sleep_time/2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          for tag in soup.findAll(\"span\", {\"class\": \"a-size-base\"}):\n",
        "              xxxxx = tag.findNext().text\n",
        "              if len(xxxxx)>=1:\n",
        "                saver['text'].append(xxxxx)\n",
        "              else:\n",
        "                vvvv = 2\n",
        "\n",
        "          for tag in soup.findAll(\"span\", {\"data-hook\": \"review-body\"}):\n",
        "              xxxxx = tag.findNext().text\n",
        "              if len(xxxxx)>=1:\n",
        "                saver['text'].append(xxxxx)\n",
        "              else:\n",
        "                vvvv = 2\n",
        "\n",
        "          for x in range(len(saver['text'])):\n",
        "            if len(str(saver['text'][x]).split())>=50:\n",
        "              uu['text'].append(str(saver['text'][x]).lower())\n",
        "            else:\n",
        "              ff= 1\n",
        "          for xx in range(len(uu['text'])):\n",
        "            try:\n",
        "              x = str(uu['text'][xx])\n",
        "              cc['text'].append(re.sub('\\n', '', x))\n",
        "            except:\n",
        "              fd = 2\n",
        "          xt = 0\n",
        "\n",
        "          #remove #'s to run below, filters out most updates / edits to posts, but takes a long time\n",
        "          #try:\n",
        "          for x in range(len(cc['text'])):\n",
        "            #xt = xt+1 \n",
        "            #if str(cc['text'][x]).split()[0] == 'edit:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[0] == 'edit':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[1] == 'edit:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[1] == 'edit':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[2] == 'edit:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[2] == 'edit':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[3] == 'edit:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[3] == 'edit':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[4] == 'edit:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[4] == 'edit':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[0] == 'update:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[0] == 'update':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[1] == 'update:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[1] == 'update':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[2] == 'update:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[2] == 'update':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[3] == 'update:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[3] == 'update':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[4] == 'update:':\n",
        "              #ttt = 1\n",
        "            #elif str(cc['text'][x]).split()[4] == 'update':\n",
        "              #ttt = 1\n",
        "            #else:\n",
        "              ccc['text'].append(cc['text'][x])\n",
        "          #except:\n",
        "            #dfs = 1\n",
        "\n",
        "    df_reviews = pd.DataFrame()\n",
        "    df_reviews['reviews'] = pd.DataFrame(ccc['text']).drop_duplicates()\n",
        "    df_sentence_reviews = {'sentences':[],'review_num':[]}\n",
        "    for xc in range(len(df_reviews['reviews'])):\n",
        "      try:\n",
        "        dd = str(df_reviews['reviews'][xc]).split('.')\n",
        "        dd1 = str(df_reviews['reviews'][xc+1]).split('.')\n",
        "        dd2 = str(df_reviews['reviews'][xc+2]).split('.')\n",
        "        dd3 = str(df_reviews['reviews'][xc+3]).split('.')\n",
        "        for x in range(len(dd)):\n",
        "          df_sentence_reviews['sentences'].append(str(dd[x])+str(dd1[x])+str(dd2[x])+str(dd3[x]))\n",
        "          df_sentence_reviews['review_num'].append(str(xc))\n",
        "      except:\n",
        "        dfgs = 1\n",
        "    df_sentence_reviews=pd.DataFrame(df_sentence_reviews)\n",
        "  else:\n",
        "    print('no data collection')\n",
        "\n",
        "  if topicc_model =='yes':\n",
        "    print('***TOPIC MODEL FOR XXXXX PRODUCT/BRAND***')\n",
        "    #TOPIC MODEL\n",
        "    import pandas as pd\n",
        "    import re\n",
        "    from gensim import corpora, models, similarities\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import sys\n",
        "    # !{sys.executable} -m spacy download en\n",
        "    import re, numpy as np, pandas as pd\n",
        "    from pprint import pprint\n",
        "\n",
        "    import gensim, spacy, logging, warnings\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    import gensim.corpora as corpora\n",
        "    from gensim.utils import  simple_preprocess\n",
        "    from gensim.models import CoherenceModel\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    from nltk import word_tokenize, sent_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
        "    from wordcloud import WordCloud, STOPWORDS\n",
        "    from textblob import TextBlob\n",
        "\n",
        "    from nltk.corpus import stopwords\n",
        "    stop_words=['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come']\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "    \n",
        "    df['reviews.text'] = df_sentence_reviews.sentences.astype(str).apply(lambda x: \" \".join(x.lower() for x in x.split())).apply(lambda x: \" \".join(x for x in x.split() if x not in stop)).apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "    stop = stopwords.words('english')\n",
        "    st = PorterStemmer()\n",
        "    def senti(x):\n",
        "        return TextBlob(x).sentiment  \n",
        "    df['senti_score'] = df['reviews.text'].astype(str).apply(senti)\n",
        "    xx = []\n",
        "    xy = []\n",
        "    df_sentence_reviews = pd.DataFrame(df['reviews.text'])\n",
        "    for x in range(len(df_sentence_reviews)):\n",
        "      xx.append(str(df.senti_score[x]).split(',')[0].split('=')[1])\n",
        "      xy.append(str(df.senti_score[x]).split(',')[1].split('=')[1].split(')')[0])\n",
        "    print(len(xx))\n",
        "    print(len(xy))\n",
        "    df_sentence_reviews['sentiment'] = xx\n",
        "    df_sentence_reviews['subjectivity'] = xy\n",
        "\n",
        "    if positiveOrNegative == 'positive':\n",
        "      df_sentence_reviews = df_sentence_reviews[df_sentence_reviews['sentiment'].astype(float)>=higher_we_go]\n",
        "    else:\n",
        "      df_sentence_reviews = df_sentence_reviews[df_sentence_reviews['sentiment'].astype(float)<=higher_we_go]\n",
        "\n",
        "    df_sentence_reviews\n",
        "\n",
        "    \n",
        "    \n",
        "    red_it = pd.DataFrame()\n",
        "    red_it['personal_stories'] = df_sentence_reviews['reviews.text']\n",
        "    red_it = pd.DataFrame(red_it['personal_stories'])\n",
        "\n",
        "    #---------------------------------------------------------------------------------\n",
        "\n",
        "    import gensim\n",
        "    from gensim.utils import simple_preprocess\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    from nltk.corpus import stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "    def sent_to_words(sentences):\n",
        "        for sentence in sentences:\n",
        "            yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "    def remove_stopwords(texts):\n",
        "        return [[word for word in simple_preprocess(str(doc)) \n",
        "                  if word not in stop_words] for doc in texts]\n",
        "    data = red_it.personal_stories.values.tolist()\n",
        "    data_words = list(sent_to_words(data))\n",
        "    data_words = remove_stopwords(data_words)\n",
        "\n",
        "    import gensim.corpora as corpora\n",
        "    id2word = corpora.Dictionary(data_words)\n",
        "    texts = data_words\n",
        "    corpus = [id2word.doc2bow(text) for text in texts]\n",
        "    from pprint import pprint\n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                            id2word=id2word,\n",
        "                                            num_topics=xcv)\n",
        "    pprint(lda_model.print_topics())\n",
        "    doc_lda = lda_model[corpus]\n",
        "\n",
        "\n",
        "    #---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    def sent_to_words(sentences):\n",
        "        for sent in sentences:\n",
        "            sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "            yield(sent)\n",
        "\n",
        "    data = red_it.personal_stories.values.tolist()\n",
        "    data_words = list(sent_to_words(data))\n",
        "    print(data_words[:1])\n",
        "\n",
        "\n",
        "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "\n",
        "    def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "        \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "        texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "        texts = [bigram_mod[doc] for doc in texts]\n",
        "        texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "        texts_out = []\n",
        "        for sent in texts:\n",
        "            doc = nlp(\" \".join(sent)) \n",
        "            texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "        texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "        return texts_out\n",
        "\n",
        "    data_ready = process_words(data_words)  \n",
        "\n",
        "\n",
        "    #---------------------------------------------------------------------------------\n",
        "\n",
        "    id2word = corpora.Dictionary(data_ready)\n",
        "\n",
        "    corpus = [id2word.doc2bow(text) for text in data_ready]\n",
        "\n",
        "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                                id2word=id2word,\n",
        "                                                num_topics=xcv, \n",
        "                                                random_state=100,\n",
        "                                                update_every=1,\n",
        "                                                chunksize=10,\n",
        "                                                passes=10,\n",
        "                                                alpha='symmetric',\n",
        "                                                iterations=100,\n",
        "                                                per_word_topics=True)\n",
        "\n",
        "\n",
        "    #---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "    def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
        "        sent_topics_df = pd.DataFrame()\n",
        "\n",
        "        for i, row_list in enumerate(ldamodel[corpus]):\n",
        "            row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
        "            row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "            for j, (topic_num, prop_topic) in enumerate(row):\n",
        "                if j == 0:\n",
        "                    wp = ldamodel.show_topic(topic_num)\n",
        "                    topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                    sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "                else:\n",
        "                    break\n",
        "        sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "        contents = pd.Series(texts)\n",
        "        sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "        return(sent_topics_df)\n",
        "\n",
        "\n",
        "    df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
        "\n",
        "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "    df_dominant_topic.head(10)\n",
        "\n",
        "\n",
        "\n",
        "    pd.options.display.max_colwidth = 100\n",
        "\n",
        "    sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "    sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "    for i, grp in sent_topics_outdf_grpd:\n",
        "        sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                                  grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
        "                                                axis=0)\n",
        "\n",
        "    sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
        "\n",
        "    sent_topics_sorteddf_mallet.head(10)\n",
        "\n",
        "    books_read = sent_topics_sorteddf_mallet\n",
        "\n",
        "    #---------------------------------------------------------------------------------\n",
        "\n",
        "    from matplotlib import pyplot as plt\n",
        "    from wordcloud import WordCloud, STOPWORDS\n",
        "    import matplotlib.colors as mcolors\n",
        "\n",
        "    cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
        "\n",
        "    cloud = WordCloud(stopwords=stop_words,\n",
        "                      background_color='white',\n",
        "                      width=2500,\n",
        "                      height=1800,\n",
        "                      max_words=20,\n",
        "                      colormap='tab10',\n",
        "                      color_func=lambda *args, **kwargs: cols[i],\n",
        "                      prefer_horizontal=1.0)\n",
        "\n",
        "    topics = lda_model.show_topics(formatted=False)\n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(20,20), sharex=True, sharey=True)\n",
        "    try:\n",
        "      for i, ax in enumerate(axes.flatten()):\n",
        "        fig.add_subplot(ax)\n",
        "        topic_words = dict(topics[i][1])\n",
        "        cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
        "        plt.gca().imshow(cloud)\n",
        "        plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=xcv))\n",
        "        plt.gca().axis('off')\n",
        "    except:\n",
        "        dffd = 1\n",
        "\n",
        "    try:\n",
        "      plt.subplots_adjust(wspace=0, hspace=0)\n",
        "      plt.axis('off')\n",
        "      plt.margins(x=0, y=0)\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "    except:\n",
        "      dffd = 1\n",
        "\n",
        "    #---------------------------------------------------------------------------------\n",
        "\n",
        "    from collections import Counter\n",
        "    topics = lda_model.show_topics(formatted=False)\n",
        "    data_flat = [w for w_list in data_ready for w in w_list]\n",
        "    counter = Counter(data_flat)\n",
        "\n",
        "    out = []\n",
        "    for i, topic in topics:\n",
        "        for word, weight in topic:\n",
        "            out.append([word, i , weight, counter[word]])\n",
        "\n",
        "    df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(20,20), sharey=True, dpi=160)\n",
        "    cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
        "    try:\n",
        "      for i, ax in enumerate(axes.flatten()):\n",
        "          ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
        "          ax_twin = ax.twinx()\n",
        "          ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
        "          ax.set_ylabel('Word Count', color=cols[i])\n",
        "          ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
        "          ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
        "          ax.tick_params(axis='y', left=False)\n",
        "          ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
        "          ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
        "\n",
        "      fig.tight_layout(w_pad=2)    \n",
        "      fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)   \n",
        "      plt.show()\n",
        "      \n",
        "    except:\n",
        "      fwf = 1\n",
        "  else:\n",
        "    print('no topic model')\n",
        "\n",
        "  print(df_reviews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a12ofhs8hOKL",
        "outputId": "8cb409ab-028f-46b5-abc5-a6213feacb0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run in default mode (yes/no)\n",
            "yes\n",
            "run data collection? (yes/no)\n",
            "yes\n",
            "run topic model? (yes/no)\n",
            "yes\n",
            "enter your level (1-10)\n",
            "HIGH GPU FOR LABELS>3\n",
            "2\n",
            "enter sleep time, .1s reccommended (3s for levels>10)\n",
            ".1\n",
            "enter your preferred # of topics for the topic model:\n",
            "10\n",
            "how many products would you like to analyze?\n",
            "1\n",
            "would you like to analyze positive or negative reviews? (positive/negative)\n",
            "positive\n",
            "min positive sentiment or max negative sentiment you would like to analyze, depending on the answer to your question above\n",
            "-1 to 1, .2/-.2 reccomended, the more extreme the parameters the higher your level should be!\n",
            ".1\n",
            "enter the product type / brand reviews you would like to analyze\n",
            "starbucks coffee pods\n",
            "length of product pages collected: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'reviews'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3750\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3751\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3752\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'reviews'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-032e05a20257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mdf_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mdf_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0mdf_sentence_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'review_num'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3601\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3602\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3603\u001b[0m         elif (\n\u001b[1;32m   3604\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3740\u001b[0m         \u001b[0;31m# now align rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m         \u001b[0marraylike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3742\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iset_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mslice\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3752\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3753\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3754\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_block_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, klass)\u001b[0m\n\u001b[1;32m   1935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_pandas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m     \u001b[0mcheck_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcheck_ndim\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1980\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1981\u001b[0m                 \u001b[0;34mf\"placement implies {len(placement)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 0, placement implies 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentence_reviews.astype(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OE38ZyOUH4hc",
        "outputId": "2943dd41-52f0-4453-ca52-d93b16e167f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                              sentences  \\\n",
              "0   this starbucks k-cup is a lighter caffeinated coffee and is a perfect first cup of coffee in the...   \n",
              "1    this is a mellow and relaxed cup of coffee  i contacted starbucks and they informed me that all...   \n",
              "2    (as a light roast, it has more caffeine than a darker roast  i have replied to them that there ...   \n",
              "3   ) this starbucks blonde roast includes hints of soft cocoa and lightly toasted nuts  plus your p...   \n",
              "4    i dont like heavy strong coffee i'm confused and concerned! i'm confused and concerned!  furthe...   \n",
              "..                                                                                                  ...   \n",
              "75    i just bought these because i like pike's place  okay, we have this starbucks flavor set up fo...   \n",
              "76   the price was really good so i bought two cases  however, i feel i need to after this last deli...   \n",
              "77   each contained 6 boxes of 10 pods  first couple of times i ordered, the product was fine  by th...   \n",
              "78   when i rec'd today i noticed that the best by date on all 12 boxes is next month$15 price flux ...   \n",
              "79   should have wondered why the price was good a loyal customer who buys the same products every m...   \n",
              "\n",
              "   review_num  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "..        ...  \n",
              "75        281  \n",
              "76        281  \n",
              "77        281  \n",
              "78        281  \n",
              "79        281  \n",
              "\n",
              "[80 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-012e5bdf-652a-42be-9120-266d7bbdef2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>review_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this starbucks k-cup is a lighter caffeinated coffee and is a perfect first cup of coffee in the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is a mellow and relaxed cup of coffee  i contacted starbucks and they informed me that all...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(as a light roast, it has more caffeine than a darker roast  i have replied to them that there ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>) this starbucks blonde roast includes hints of soft cocoa and lightly toasted nuts  plus your p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i dont like heavy strong coffee i'm confused and concerned! i'm confused and concerned!  furthe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>i just bought these because i like pike's place  okay, we have this starbucks flavor set up fo...</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>the price was really good so i bought two cases  however, i feel i need to after this last deli...</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>each contained 6 boxes of 10 pods  first couple of times i ordered, the product was fine  by th...</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>when i rec'd today i noticed that the best by date on all 12 boxes is next month$15 price flux ...</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>should have wondered why the price was good a loyal customer who buys the same products every m...</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-012e5bdf-652a-42be-9120-266d7bbdef2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-012e5bdf-652a-42be-9120-266d7bbdef2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-012e5bdf-652a-42be-9120-266d7bbdef2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviews.text'] = df_sentence_reviews['reviews.text'].astype(str)\n",
        "df['reviews.text'] = df['reviews.text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "stop = stopwords.words('english')\n",
        "df['reviews.text'] = df['reviews.text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "st = PorterStemmer()\n",
        "df['reviews.text'] = df['reviews.text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "def senti(x):\n",
        "    return TextBlob(x).sentiment  \n",
        "df['senti_score'] = df['reviews.text'].apply(senti)\n",
        "xx = []\n",
        "xy = []\n",
        "df_sentence_reviews = pd.DataFrame(df['reviews.text'])\n",
        "for x in range(len(df_sentence_reviews)):\n",
        "  xx.append(str(df.senti_score[x]).split(',')[0].split('=')[1])\n",
        "  xy.append(str(df.senti_score[x]).split(',')[1].split('=')[1].split(')')[0])\n",
        "print(len(xx))\n",
        "print(len(xy))\n",
        "df_sentence_reviews['sentiment'] = xx\n",
        "df_sentence_reviews['subjectivity'] = xy\n",
        "\n",
        "print('would you like to analyze positive or negative reviews? (positive/negative)')\n",
        "positiveOrNegative = input().lower()\n",
        "print('min positive sentiment or max negative sentiment you would like to analyze, depending on the answer to your question above')\n",
        "print('-1 to 1, .2/-.2 reccomended, the more extreme the parameters the higher your level should be!')\n",
        "higher_we_go = int(input())\n",
        "if positiveOrNegative == 'positive':\n",
        "  df_sentence_reviews = df_sentence_reviews[df_sentence_reviews['sentiment'].astype(float)>=higher_we_go]\n",
        "else:\n",
        "  df_sentence_reviews = df_sentence_reviews[df_sentence_reviews['sentiment'].astype(float)<=higher_we_go]\n",
        "\n",
        "df_sentence_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "AL5U0cGD7nUE",
        "outputId": "93a7f96e-97cc-4a4a-fbac-c75c6965c337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-667983ddf8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sentence_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-667983ddf8d0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sentence_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviews.text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlPKsw-DGYVO",
        "outputId": "f39a6d6e-7332-4fac-b7b5-6a88d6b71613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                                                     NaN\n",
              "1     clean regularli use daili nespresso brand capsul clean regularli use daili nespresso brand capsu...\n",
              "2     saw pass deal, $ saw pass deal, $ piti hope possibl enjoy food coff lower price nespresso seriou...\n",
              "3                                                                                                     NaN\n",
              "4                                                                                   75 $75 $ much lighter\n",
              "                                                     ...                                                 \n",
              "95    decid enough posit review give shot one cup abl squeez pretti good flavor work machin qualiti co...\n",
              "96                                                                                                    NaN\n",
              "97    tri pierc foil manual put machin let' ground machin clog cup well first problem number capsul fo...\n",
              "98                                                                                                    NaN\n",
              "99                                                                                                    NaN\n",
              "Name: reviews.text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "grSTrM8iCgIw",
        "outputId": "74d0ed2b-5791-43b9-9621-7ed1744abf08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                           reviews.text  \\\n",
              "0   we've had our nespresso for a decade with no issues  we've had our nespresso for a decade with n...   \n",
              "1     we clean it regularly and have used it daily with nespresso brand capsules  we clean it regula...   \n",
              "2     we saw these and couldn't pass up the deal, $  we saw these and couldn't pass up the deal, $ t...   \n",
              "3   33 compared to $33 compared to $ when the coffee started to dispense, i noticed a significant co...   \n",
              "4                                                                           75 or $75 or $ much lighter   \n",
              "..                                                                                                  ...   \n",
              "95   i decided there were enough positive reviews to give them a shot and the one cup i was able to ...   \n",
              "96   the foil on top doesn't pierce in the machine so back pressure builds up and makes water leak a...   \n",
              "97   i tried piercing the foil manually before putting in the machine but that let's grounds through...   \n",
              "98   also, the back or bottom of capsule has it's own 'vents' that open but they dont align with the...   \n",
              "99    maybe 1/3 of the water dispensed from machine, actually makes it through the capsule and into ...   \n",
              "\n",
              "              sentiment         subjectivity  \n",
              "0                   0.0                 0.05  \n",
              "1   0.24444444444444446                 0.55  \n",
              "2   0.12333333333333334  0.37333333333333335  \n",
              "3                   0.0                  0.0  \n",
              "4                   0.2                  0.2  \n",
              "..                  ...                  ...  \n",
              "95                 0.25  0.44000000000000006  \n",
              "96                  0.0               0.4375  \n",
              "97                0.475   0.4666666666666667  \n",
              "98  0.06666666666666667   0.3458333333333334  \n",
              "99  0.12159090909090908   0.2761363636363636  \n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c4fa43b-a233-4911-9304-3604a9134569\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we've had our nespresso for a decade with no issues  we've had our nespresso for a decade with n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we clean it regularly and have used it daily with nespresso brand capsules  we clean it regula...</td>\n",
              "      <td>0.24444444444444446</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we saw these and couldn't pass up the deal, $  we saw these and couldn't pass up the deal, $ t...</td>\n",
              "      <td>0.12333333333333334</td>\n",
              "      <td>0.37333333333333335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33 compared to $33 compared to $ when the coffee started to dispense, i noticed a significant co...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75 or $75 or $ much lighter</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>i decided there were enough positive reviews to give them a shot and the one cup i was able to ...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.44000000000000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>the foil on top doesn't pierce in the machine so back pressure builds up and makes water leak a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>i tried piercing the foil manually before putting in the machine but that let's grounds through...</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.4666666666666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>also, the back or bottom of capsule has it's own 'vents' that open but they dont align with the...</td>\n",
              "      <td>0.06666666666666667</td>\n",
              "      <td>0.3458333333333334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>maybe 1/3 of the water dispensed from machine, actually makes it through the capsule and into ...</td>\n",
              "      <td>0.12159090909090908</td>\n",
              "      <td>0.2761363636363636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c4fa43b-a233-4911-9304-3604a9134569')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c4fa43b-a233-4911-9304-3604a9134569 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c4fa43b-a233-4911-9304-3604a9134569');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lKip3C6fivak",
        "outputId": "9500b9eb-dd9d-4a7b-cf22-3f72f80010b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                           reviews.text\n",
              "0   we've had our nespresso for a decade with no issues  we've had our nespresso for a decade with n...\n",
              "1     we clean it regularly and have used it daily with nespresso brand capsules  we clean it regula...\n",
              "2     we saw these and couldn't pass up the deal, $  we saw these and couldn't pass up the deal, $ t...\n",
              "3   33 compared to $33 compared to $ when the coffee started to dispense, i noticed a significant co...\n",
              "4                                                                           75 or $75 or $ much lighter\n",
              "..                                                                                                  ...\n",
              "95   i decided there were enough positive reviews to give them a shot and the one cup i was able to ...\n",
              "96   the foil on top doesn't pierce in the machine so back pressure builds up and makes water leak a...\n",
              "97   i tried piercing the foil manually before putting in the machine but that let's grounds through...\n",
              "98   also, the back or bottom of capsule has it's own 'vents' that open but they dont align with the...\n",
              "99    maybe 1/3 of the water dispensed from machine, actually makes it through the capsule and into ...\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc7e0c34-2bb0-4a1d-b26e-af40d76ecf2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews.text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we've had our nespresso for a decade with no issues  we've had our nespresso for a decade with n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we clean it regularly and have used it daily with nespresso brand capsules  we clean it regula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we saw these and couldn't pass up the deal, $  we saw these and couldn't pass up the deal, $ t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33 compared to $33 compared to $ when the coffee started to dispense, i noticed a significant co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75 or $75 or $ much lighter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>i decided there were enough positive reviews to give them a shot and the one cup i was able to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>the foil on top doesn't pierce in the machine so back pressure builds up and makes water leak a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>i tried piercing the foil manually before putting in the machine but that let's grounds through...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>also, the back or bottom of capsule has it's own 'vents' that open but they dont align with the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>maybe 1/3 of the water dispensed from machine, actually makes it through the capsule and into ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc7e0c34-2bb0-4a1d-b26e-af40d76ecf2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc7e0c34-2bb0-4a1d-b26e-af40d76ecf2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc7e0c34-2bb0-4a1d-b26e-af40d76ecf2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf['dd']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8YKhX3wBlWB",
        "outputId": "4d7d3061-40b9-4ade-d3e2-4cd396c83add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     we've had our nespresso for a decade with no issues  we've had our nespresso for a decade with n...\n",
              "1       we clean it regularly and have used it daily with nespresso brand capsules  we clean it regula...\n",
              "2       we saw these and couldn't pass up the deal, $  we saw these and couldn't pass up the deal, $ t...\n",
              "3     33 compared to $33 compared to $ when the coffee started to dispense, i noticed a significant co...\n",
              "4                                                                             75 or $75 or $ much lighter\n",
              "                                                     ...                                                 \n",
              "95     i decided there were enough positive reviews to give them a shot and the one cup i was able to ...\n",
              "96     the foil on top doesn't pierce in the machine so back pressure builds up and makes water leak a...\n",
              "97     i tried piercing the foil manually before putting in the machine but that let's grounds through...\n",
              "98     also, the back or bottom of capsule has it's own 'vents' that open but they dont align with the...\n",
              "99      maybe 1/3 of the water dispensed from machine, actually makes it through the capsule and into ...\n",
              "Name: dd, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yS0OiA-IBllp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_sentence_reviews.sentences)"
      ],
      "metadata": {
        "id": "7vErwWbUhO7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34a0a9f-fddb-4339-e6e1-fa93fba9d4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m2fss4gvhO-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_pCvegi-hPB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import requests \n",
        "import time \n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import re\n",
        "\n",
        "#shared link: https://colab.research.google.com/drive/1LJoBqfg7phAfMmFsTX_-Ng0MPczdP7VS?usp=sharing\n",
        "\n",
        "#set default\n",
        "session_idd = '132-9175929-1227644'\n",
        "tolkienn = 'ZeucQ3BN0LOLP+CsvILZAlMW+TYX0HrsjLnkSK7iWMe8nmyie4YKkvi4E1E0GGP5n4dy72gLt2eLdYgQdQwBQH3XrH4gnXUTYa5xAV22asPAthhmzrzZF+lJrFkuQat5+sJq2QqG3rqCQAR0zTo/oUX2HextqvZd46uYHtVvVxtmnwCRqn9SmaeQQ6qsImC3'\n",
        "\n",
        "\n",
        "print('run in default mode (yes/no)')\n",
        "default = input().lower()\n",
        "if default == 'yes':\n",
        "  session_id = session_idd\n",
        "  tolkien = tolkienn\n",
        "  print('run data collection? (yes/no)')\n",
        "  data_collection = input().lower()\n",
        "  print('run topic model? (yes/no)')\n",
        "  topicc_model = input().lower()\n",
        "  print('enter your level (1-10)')\n",
        "  print('HIGH GPU FOR LABELS>3')\n",
        "  level =int(input())\n",
        "  print('enter sleep time (must be an integer), 1s reccommended (5s for levels>10)')\n",
        "  sleep_time = float(input())\n",
        "  print('enter your preferred # of topics for the topic model:')\n",
        "  xcv = int(input())\n",
        "else:\n",
        "  print('enter your token (paste)')\n",
        "  tolkien = input()\n",
        "  print('enter your session id')\n",
        "  session_id = input()\n",
        "  print('run data collection? (yes/no)')\n",
        "  data_collection = input().lower()\n",
        "  print('run topic model? (yes/no)')\n",
        "  topicc_model = input().lower()\n",
        "  print('enter your level (1-10)')\n",
        "  level = int(input())\n",
        "  print('enter sleep time (must be an integer), 1s reccommended (5s for levels>10)')\n",
        "  sleep_time = float(input())\n",
        "  print('enter your preferred # of topics for the topic model:')\n",
        "  xcv = int(input())\n",
        "\n",
        "saver = {'review':[],'title':[],'verified':[],'text':[]}\n",
        "uu = {'text':[]}\n",
        "ccc = {'text':[]}\n",
        "cc = {'text':[]}\n",
        "saverr = {'links':[]}\n",
        "cust_rev = {'id':[],'name':[],'link':[]}\n",
        "reviews = {'name':[],'id':[]}\n",
        "\n",
        "\n",
        "if data_collection =='yes':\n",
        "  level = level*3\n",
        "  print('enter the product type / brand reviews you would like to analyze')\n",
        "  sss = str(input())\n",
        "  for xzx in range(2):\n",
        "    url = 'https://www.amazon.com/s?k='+sss+':&page='+str(xzx)\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36'}\n",
        "    cookies = {'session-id':session_id,'session-id-time':'2082787201l','i18n-prefs':'USD','csm-hit':'tb:s-1KBXPV9W0G7AT013EMW9|1648478470844&t:1648478472672&adb:adblk_no','ubid-main':'132-0411939-8328406','session-token':tolkien}\n",
        "    html = requests.get(url,headers = headers, cookies =cookies).text\n",
        "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "    time.sleep(sleep_time)\n",
        "    \n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"s-main-slot s-result-list s-search-results sg-row\"}):\n",
        "      xxxx = tag.findAll(\"a\",{\"class\":\"a-link-normal\"})\n",
        "      if len(xxxx)>=1:\n",
        "        saverr['links'].append(xxxx)\n",
        "      else:\n",
        "        print(xxxx)\n",
        "    print('length of product pages collected: '+str(len(saverr['links'])))\n",
        "  from numpy.ma.core import exp\n",
        "  for xc in range(len(str(saverr['links'][0]).split('\" href=\"/'))):\n",
        "    try:\n",
        "      cust_rev['id'].append(str(saverr['links'][0]).split(';url=%2F')[xc].split('%2F')[2])\n",
        "      cust_rev['name'].append(str(saverr['links'][0]).split(';url=%2F')[xc].split('%2F')[0])\n",
        "    except:\n",
        "      cvc = 2\n",
        "\n",
        "  reviews = pd.DataFrame()\n",
        "  reviews['id'] = pd.DataFrame(cust_rev['id']).drop_duplicates()\n",
        "  reviews['name'] = pd.DataFrame(cust_rev['name']).drop_duplicates()\n",
        "  reviews['link'] = pd.DataFrame(cust_rev['name']).drop_duplicates()\n",
        "  reviews = reviews.reset_index().drop(columns = 'index')\n",
        "\n",
        "  for xi in range(len(reviews)):\n",
        "      reviews['link'].iloc[xi] = 'https://www.amazon.com/'+str(reviews['name'][xi])+'/product-reviews/'+str(reviews['id'][xi])+'/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'\n",
        "\n",
        "  for xv in range(len(reviews['link'])):\n",
        "    for xvv in range(level*3):\n",
        "        xvv = xvv+1\n",
        "        html = requests.get(str(reviews['link'][xv])+'=all_reviews&pageNumber='+str(xvv),headers = headers, cookies =cookies).text\n",
        "        soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "        time.sleep(sleep_time/2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for tag in soup.findAll(\"span\", {\"class\": \"a-size-base\"}):\n",
        "            xxxxx = tag.findNext().text\n",
        "            if len(xxxxx)>=1:\n",
        "              saver['text'].append(xxxxx)\n",
        "            else:\n",
        "              vvvv = 2\n",
        "\n",
        "        for tag in soup.findAll(\"span\", {\"data-hook\": \"review-body\"}):\n",
        "            xxxxx = tag.findNext().text\n",
        "            if len(xxxxx)>=1:\n",
        "              saver['text'].append(xxxxx)\n",
        "            else:\n",
        "              vvvv = 2\n",
        "\n",
        "        for x in range(len(saver['text'])):\n",
        "          if len(str(saver['text'][x]).split())>=50:\n",
        "            uu['text'].append(str(saver['text'][x]).lower())\n",
        "          else:\n",
        "            ff= 1\n",
        "        for xx in range(len(uu['text'])):\n",
        "          try:\n",
        "            x = str(uu['text'][xx])\n",
        "            cc['text'].append(re.sub('\\n', '', x))\n",
        "          except:\n",
        "            fd = 2\n",
        "        xt = 0\n",
        "\n",
        "        #remove #'s to run below, filters out most updates / edits to posts, but takes a long time\n",
        "        #try:\n",
        "        for x in range(len(cc['text'])):\n",
        "          #xt = xt+1 \n",
        "          #if str(cc['text'][x]).split()[0] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[0] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[0] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[0] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'update':\n",
        "            #ttt = 1\n",
        "          #else:\n",
        "            ccc['text'].append(cc['text'][x])\n",
        "        #except:\n",
        "          #dfs = 1\n",
        "\n",
        "  df_reviews = pd.DataFrame()\n",
        "  df_reviews['reviews'] = pd.DataFrame(ccc['text']).drop_duplicates()\n",
        "  df_sentence_reviews = {'sentences':[],'review_num':[]}\n",
        "  for xc in range(len(df_reviews['reviews'])):\n",
        "    try:\n",
        "      dd = str(df_reviews['reviews'][xc]).split('.')\n",
        "      dd1 = str(df_reviews['reviews'][xc+1]).split('.')\n",
        "      dd2 = str(df_reviews['reviews'][xc+2]).split('.')\n",
        "      dd3 = str(df_reviews['reviews'][xc+3]).split('.')\n",
        "      for x in range(len(dd)):\n",
        "        df_sentence_reviews['sentences'].append(str(dd[x])+str(dd1[x])+str(dd2[x])+str(dd3[x]))\n",
        "        df_sentence_reviews['review_num'].append(str(xc))\n",
        "    except:\n",
        "      dfgs = 1\n",
        "  df_sentence_reviews=pd.DataFrame(df_sentence_reviews)\n",
        "else:\n",
        "  print('no data collection')\n",
        "\n",
        "if topicc_model =='yes':\n",
        "  print('***TOPIC MODEL FOR XXXXX PRODUCT/BRAND***')\n",
        "  #TOPIC MODEL\n",
        "  import pandas as pd\n",
        "  import re\n",
        "  from gensim import corpora, models, similarities\n",
        "  import nltk\n",
        "  from nltk.corpus import stopwords\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import sys\n",
        "  # !{sys.executable} -m spacy download en\n",
        "  import re, numpy as np, pandas as pd\n",
        "  from pprint import pprint\n",
        "\n",
        "  import gensim, spacy, logging, warnings\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  import gensim.corpora as corpora\n",
        "  from gensim.utils import  simple_preprocess\n",
        "  from gensim.models import CoherenceModel\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words=['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come']\n",
        "\n",
        "  warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "  logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "  red_it = pd.DataFrame()\n",
        "  red_it['personal_stories'] = df_sentence_reviews['sentences']\n",
        "  red_it = pd.DataFrame(red_it['personal_stories'])\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = red_it.personal_stories.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_words = remove_stopwords(data_words)\n",
        "\n",
        "  import gensim.corpora as corpora\n",
        "  id2word = corpora.Dictionary(data_words)\n",
        "  texts = data_words\n",
        "  corpus = [id2word.doc2bow(text) for text in texts]\n",
        "  from pprint import pprint\n",
        "  lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                          id2word=id2word,\n",
        "                                          num_topics=xcv)\n",
        "  pprint(lda_model.print_topics())\n",
        "  doc_lda = lda_model[corpus]\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  data = red_it.personal_stories.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  print(data_words[:1])\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  id2word = corpora.Dictionary(data_ready)\n",
        "\n",
        "  corpus = [id2word.doc2bow(text) for text in data_ready]\n",
        "\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                              id2word=id2word,\n",
        "                                              num_topics=xcv, \n",
        "                                              random_state=100,\n",
        "                                              update_every=1,\n",
        "                                              chunksize=10,\n",
        "                                              passes=10,\n",
        "                                              alpha='symmetric',\n",
        "                                              iterations=100,\n",
        "                                              per_word_topics=True)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "  def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
        "      sent_topics_df = pd.DataFrame()\n",
        "\n",
        "      for i, row_list in enumerate(ldamodel[corpus]):\n",
        "          row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
        "          row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "          for j, (topic_num, prop_topic) in enumerate(row):\n",
        "              if j == 0:\n",
        "                  wp = ldamodel.show_topic(topic_num)\n",
        "                  topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "              else:\n",
        "                  break\n",
        "      sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "      contents = pd.Series(texts)\n",
        "      sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "      return(sent_topics_df)\n",
        "\n",
        "\n",
        "  df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
        "\n",
        "  df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "  df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "  df_dominant_topic.head(10)\n",
        "\n",
        "\n",
        "\n",
        "  pd.options.display.max_colwidth = 100\n",
        "\n",
        "  sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "  sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "  for i, grp in sent_topics_outdf_grpd:\n",
        "      sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                                grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
        "                                              axis=0)\n",
        "\n",
        "  sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
        "\n",
        "  sent_topics_sorteddf_mallet.head(10)\n",
        "\n",
        "  books_read = sent_topics_sorteddf_mallet\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  from matplotlib import pyplot as plt\n",
        "  from wordcloud import WordCloud, STOPWORDS\n",
        "  import matplotlib.colors as mcolors\n",
        "\n",
        "  cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
        "\n",
        "  cloud = WordCloud(stopwords=stop_words,\n",
        "                    background_color='white',\n",
        "                    width=2500,\n",
        "                    height=1800,\n",
        "                    max_words=20,\n",
        "                    colormap='tab10',\n",
        "                    color_func=lambda *args, **kwargs: cols[i],\n",
        "                    prefer_horizontal=1.0)\n",
        "\n",
        "  topics = lda_model.show_topics(formatted=False)\n",
        "\n",
        "  fig, axes = plt.subplots(4, 4, figsize=(20,20), sharex=True, sharey=True)\n",
        "  try:\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "      fig.add_subplot(ax)\n",
        "      topic_words = dict(topics[i][1])\n",
        "      cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
        "      plt.gca().imshow(cloud)\n",
        "      plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
        "      plt.gca().axis('off')\n",
        "  except:\n",
        "      dffd = 1\n",
        "\n",
        "  try:\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.axis('off')\n",
        "    plt.margins(x=0, y=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "  except:\n",
        "    dffd = 1\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  from collections import Counter\n",
        "  topics = lda_model.show_topics(formatted=False)\n",
        "  data_flat = [w for w_list in data_ready for w in w_list]\n",
        "  counter = Counter(data_flat)\n",
        "\n",
        "  out = []\n",
        "  for i, topic in topics:\n",
        "      for word, weight in topic:\n",
        "          out.append([word, i , weight, counter[word]])\n",
        "\n",
        "  df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
        "\n",
        "  fig, axes = plt.subplots(4, 4, figsize=(20,20), sharey=True, dpi=160)\n",
        "  cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
        "  try:\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
        "        ax_twin = ax.twinx()\n",
        "        ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
        "        ax.set_ylabel('Word Count', color=cols[i])\n",
        "        ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
        "        ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
        "        ax.tick_params(axis='y', left=False)\n",
        "        ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
        "        ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
        "\n",
        "    fig.tight_layout(w_pad=2)    \n",
        "    fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)   \n",
        "    plt.show()\n",
        "  except:\n",
        "    fwf = 1\n",
        "else:\n",
        "  print('no topic model')\n",
        "\n",
        "df_reviews\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIoHvACbtGZi",
        "outputId": "05c916b5-ce25-42e4-ed4a-1a3f81b20351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run in default mode (yes/no)\n",
            "yes\n",
            "run data collection? (yes/no)\n",
            "yes\n",
            "run topic model? (yes/no)\n",
            "yes\n",
            "enter your level (1-10)\n",
            "HIGH GPU FOR LABELS>3\n",
            "3\n",
            "enter sleep time (must be an integer), 1s reccommended (5s for levels>10)\n",
            "3\n",
            "enter your preferred # of topics for the topic model:\n",
            "10\n",
            "enter the product type / brand reviews you would like to analyze\n",
            "apple airpods\n",
            "length of product pages collected: 1\n",
            "length of product pages collected: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1k-Xk3xz2Tz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'https://www.amazon.com/'+str(reviews['name'][xi])+'/product-reviews/'+str(reviews['id'][xi])+'/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "UKF9jKwuu3th",
        "outputId": "9b5d7919-8b14-4837-a71a-a606d0dc4791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.amazon.com/Qietopeb-Joggers-Sweatpants-Athletic-Workout/product-reviews/B09Q6BXXTY/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cust_rev = pd.DataFrame(cust_rev['name'])"
      ],
      "metadata": {
        "id": "i1ikKE9Dt1tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_rev[0][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pTFtiuu_uCEZ",
        "outputId": "c6694608-1862-4e39-85f6-e82f454982b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GYM-PEOPLE-Loose-fit-Sweatpants-Lined-Black'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentence_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nkwPKDEpA0m_",
        "outputId": "10ccc542-16d3-4c50-def2-03225fb45361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                               sentences  \\\n",
              "0    these little things pack one hell of a punch!appleâ€™s new noise cancellation and transparency mod...   \n",
              "1     yes others may have used similar technology before, but appleâ€™s simplistic ui made for the airp...   \n",
              "2                         coming from the first generation airpods, the experience is like night and day   \n",
              "3     even though the airpods themselves are heavier, they feel lighter in the ears and much more com...   \n",
              "4           the audio quality is insane, and this quality is only amplified by appleâ€™s new spatial audio   \n",
              "..                                                                                                   ...   \n",
              "155                                         i tried all the methods i can find online but nothing worked   \n",
              "156   my other earbuds from jabra don't look as good as airpods but more reliable (almost never dropp...   \n",
              "157           i guess they are typical apple products; looking good but low quality, and break down fast   \n",
              "158                                                                               i am glad i can return   \n",
              "159                                                                                                        \n",
              "\n",
              "    review_num  \n",
              "0            0  \n",
              "1            0  \n",
              "2            0  \n",
              "3            0  \n",
              "4            0  \n",
              "..         ...  \n",
              "155        146  \n",
              "156        146  \n",
              "157        146  \n",
              "158        146  \n",
              "159        146  \n",
              "\n",
              "[160 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b201146-d8ac-4ca8-80fe-6a738b87ab17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>review_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>these little things pack one hell of a punch!appleâ€™s new noise cancellation and transparency mod...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes others may have used similar technology before, but appleâ€™s simplistic ui made for the airp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coming from the first generation airpods, the experience is like night and day</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>even though the airpods themselves are heavier, they feel lighter in the ears and much more com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the audio quality is insane, and this quality is only amplified by appleâ€™s new spatial audio</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>i tried all the methods i can find online but nothing worked</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>my other earbuds from jabra don't look as good as airpods but more reliable (almost never dropp...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>i guess they are typical apple products; looking good but low quality, and break down fast</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>i am glad i can return</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td></td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b201146-d8ac-4ca8-80fe-6a738b87ab17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b201146-d8ac-4ca8-80fe-6a738b87ab17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b201146-d8ac-4ca8-80fe-6a738b87ab17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RvHvimPSA094"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8PYXNFSiWQII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HTBTPdW40TXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O8AkciNM0TbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pEB48Nfq0Tke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PolaM-8A0Tnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t-jNtIux0Tp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jO-NxBYK0T90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LvR3_Pk_0UBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "odqK1pFe0UFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YPQZ3-fQ0UKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZUeZN_2c0UNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pd.DataFrame(cc['text']).drop_duplicates())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNmd72OJSjmr",
        "outputId": "2a8e96e3-2ca1-4703-b172-618b424ad41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ORA8sDpQtYeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rn3f9tkmtYhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZPP_rIj5tYj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yes\n"
      ],
      "metadata": {
        "id": "4cwtXF8DtYn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews = pd.DataFrame()\n",
        "df_reviews['reviews'] = ['hello. my name is will. i like lacrosse. i am in class.','hello. my name is will. i like lacrosse. i am in class.','hello. my name is will. i like lacrosse. i am in class.']"
      ],
      "metadata": {
        "id": "gN2glEIQruWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "lI4GMDJ3sJP3",
        "outputId": "7b8cff48-4f2e-47d1-91c2-399f11008804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             reviews\n",
              "0  hello. my name is will. i like lacrosse. i am ...\n",
              "1  hello. my name is will. i like lacrosse. i am ...\n",
              "2  hello. my name is will. i like lacrosse. i am ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e3638f2-2d6d-4165-b26a-5f503cd92e8b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hello. my name is will. i like lacrosse. i am ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hello. my name is will. i like lacrosse. i am ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hello. my name is will. i like lacrosse. i am ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e3638f2-2d6d-4165-b26a-5f503cd92e8b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e3638f2-2d6d-4165-b26a-5f503cd92e8b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e3638f2-2d6d-4165-b26a-5f503cd92e8b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kWclzp46qwsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_sentence_reviews=pd.DataFrame(df_sentence_reviews)"
      ],
      "metadata": {
        "id": "nZrnV3V2h6hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentence_reviews"
      ],
      "metadata": {
        "id": "RxO9CQ4Y0i3L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "24e28e05-62ea-4296-af57-b06eee4d4f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           sentences review_num\n",
              "0              hello          0\n",
              "1    my name is will          0\n",
              "2    i like lacrosse          0\n",
              "3      i am in class          0\n",
              "4                             0\n",
              "5              hello          1\n",
              "6    my name is will          1\n",
              "7    i like lacrosse          1\n",
              "8      i am in class          1\n",
              "9                             1\n",
              "10             hello          2\n",
              "11   my name is will          2\n",
              "12   i like lacrosse          2\n",
              "13     i am in class          2\n",
              "14                            2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a03c9d62-c1ea-4f1e-8cb9-14c10b273215\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>review_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hello</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my name is will</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i like lacrosse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am in class</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hello</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>my name is will</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i like lacrosse</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i am in class</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>hello</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>my name is will</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i like lacrosse</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i am in class</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a03c9d62-c1ea-4f1e-8cb9-14c10b273215')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a03c9d62-c1ea-4f1e-8cb9-14c10b273215 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a03c9d62-c1ea-4f1e-8cb9-14c10b273215');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IaoTscvQ0i9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xPzy1VqV0jAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9y3TpWt70jDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import re\n",
        "\n",
        "#shared link: https://colab.research.google.com/drive/1LJoBqfg7phAfMmFsTX_-Ng0MPczdP7VS?usp=sharing\n",
        "\n",
        "#set default\n",
        "session_idd = '132-9175929-1227644'\n",
        "tolkienn = 'gJyDLjpbomezzfMa38sGxKQL4hFezB9Ete1MLEepKBdmkw2/yodZrKRI5vFkc/cW8w6nBbT3xzfQY6YGDRMUDh3bMQictuBgED7yNzjOoY93osg2vtbaB4RCxnlIMFIz+cRYhvFPpziQsgw+GsAFmKHjjd/wXtTRklkPsUT/XE2XxFlLUkeeE5eqiyEUCt59;csm-hit=tb:s-7Z3VSTXFGG2AM2VVR7V3|1648484703426&t:1648484706492&adb'\n",
        "\n",
        "\n",
        "print('run in default mode (yes/no)')\n",
        "default = input().lower()\n",
        "if default == 'yes':\n",
        "  session_id = session_idd\n",
        "  tolkien = tolkienn\n",
        "  print('run data collection? (yes/no)')\n",
        "  data_collection = input().lower()\n",
        "  print('run topic model? (yes/no)')\n",
        "  topicc_model = input().lower()\n",
        "  print('enter your level (1-10)')\n",
        "  print('HIGH GPU FOR LABELS>3')\n",
        "  level =int(input())\n",
        "  print('enter sleep time (must be an integer), 1s reccommended (5s for levels>10)')\n",
        "  sleep_time = float(input())\n",
        "  print('enter your preferred # of topics for the topic model:')\n",
        "  xcv = int(input())\n",
        "else:\n",
        "  print('enter your token (paste)')\n",
        "  tolkien = input()\n",
        "  print('enter your session id')\n",
        "  session_id = input()\n",
        "  print('run data collection? (yes/no)')\n",
        "  data_collection = input().lower()\n",
        "  print('run topic model? (yes/no)')\n",
        "  topicc_model = input().lower()\n",
        "  print('enter your level (1-10)')\n",
        "  level = int(input())\n",
        "  print('enter sleep time (must be an integer), 1s reccommended (5s for levels>10)')\n",
        "  sleep_time = float(input())\n",
        "  print('enter your preferred # of topics for the topic model:')\n",
        "  xcv = int(input())\n",
        "\n",
        "saver = {'review':[],'title':[],'verified':[],'text':[]}\n",
        "uu = {'text':[]}\n",
        "ccc = {'text':[]}\n",
        "cc = {'text':[]}\n",
        "saverr = {'links':[]}\n",
        "cust_rev = {'id':[],'name':[],'link':[]}\n",
        "reviews = {'name':[],'id':[]}\n",
        "\n",
        "\n",
        "if data_collection =='yes':\n",
        "  level = level*3\n",
        "  print('enter the product type / brand reviews you would like to analyze')\n",
        "  sss = str(input())\n",
        "  for xzx in range(level):\n",
        "    url = 'https://www.amazon.com/s?k='+sss+':&page='+str(xzx)\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36'}\n",
        "    cookies = {'session-id':session_id,'session-id-time':'2082787201l','i18n-prefs':'USD','csm-hit':'tb:s-1KBXPV9W0G7AT013EMW9|1648478470844&t:1648478472672&adb:adblk_no','ubid-main':'132-0411939-8328406','session-token':tolkien}\n",
        "    html = requests.get(url,headers = headers, cookies =cookies).text\n",
        "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "    time.sleep(sleep_time)\n",
        "    \n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"s-main-slot s-result-list s-search-results sg-row\"}):\n",
        "      xxxx = tag.findAll(\"a\",{\"class\":\"a-link-normal\"})\n",
        "      if len(xxxx)>=1:\n",
        "        saverr['links'].append(xxxx)\n",
        "      else:\n",
        "        print(xxxx)\n",
        "    print('length of product pages collected: '+str(len(saverr['links'])))\n",
        "  from numpy.ma.core import exp\n",
        "  for xc in range(len(str(saverr['links'][0]).split('\" href=\"/'))):\n",
        "    try:\n",
        "      cust_rev['id'].append(str(saverr['links'][0]).split(';url=%2F')[xc].split('%2F')[2])\n",
        "      cust_rev['name'].append(str(saverr['links'][0]).split(';url=%2F')[xc].split('%2F')[0])\n",
        "    except:\n",
        "      cvc = 2\n",
        "\n",
        "  reviews = pd.DataFrame()\n",
        "  reviews['id'] = cust_rev['id']\n",
        "  reviews['name'] = cust_rev['name']\n",
        "\n",
        "  for xi in range(len(reviews)):\n",
        "      cust_rev['link'].append('https://www.amazon.com/'+str(reviews['name'][xi])+'/product-reviews/'+str(reviews['id'][xi])+'/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews')\n",
        "  review_links = pd.DataFrame(cust_rev)\n",
        "\n",
        "  for xv in range(len(review_links['link'])):\n",
        "    for xvv in range(level):\n",
        "        xvv = xvv+1\n",
        "        html = requests.get(str(review_links['link'][xv])+'=all_reviews&pageNumber='+str(xvv),headers = headers, cookies =cookies).text\n",
        "        soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "        time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "\n",
        "        for tag in soup.findAll(\"span\", {\"class\": \"a-size-base\"}):\n",
        "            xxxxx = tag.findNext().text\n",
        "            if len(xxxxx)>=1:\n",
        "              saver['text'].append(xxxxx)\n",
        "            else:\n",
        "              vvvv = 2\n",
        "\n",
        "        for tag in soup.findAll(\"span\", {\"data-hook\": \"review-body\"}):\n",
        "            xxxxx = tag.findNext().text\n",
        "            if len(xxxxx)>=1:\n",
        "              saver['text'].append(xxxxx)\n",
        "            else:\n",
        "              vvvv = 2\n",
        "\n",
        "        for x in range(len(saver['text'])):\n",
        "          if len(str(saver['text'][x]).split())>=100:\n",
        "            uu['text'].append(str(saver['text'][x]).lower())\n",
        "          else:\n",
        "            ff= 1\n",
        "        for xx in range(len(uu['text'])):\n",
        "          try:\n",
        "            x = str(uu['text'][xx])\n",
        "            cc['text'].append(re.sub('\\n', '', x))\n",
        "          except:\n",
        "            fd = 2\n",
        "        xt = 0\n",
        "\n",
        "        #remove #'s to run below, filters out most updates / edits to posts, but takes a long time\n",
        "        #try:\n",
        "        for x in range(len(cc['text'])):\n",
        "          #xt = xt+1 \n",
        "          #if str(cc['text'][x]).split()[0] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[0] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'edit:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'edit':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[0] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[0] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[1] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[2] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[3] == 'update':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'update:':\n",
        "            #ttt = 1\n",
        "          #elif str(cc['text'][x]).split()[4] == 'update':\n",
        "            #ttt = 1\n",
        "          #else:\n",
        "            ccc['text'].append(cc['text'][x])\n",
        "        #except:\n",
        "          #dfs = 1\n",
        "\n",
        "  df_reviews = pd.DataFrame()\n",
        "  df_reviews['reviews'] = pd.DataFrame(ccc['text']).drop_duplicates()\n",
        "else:\n",
        "  print('no data collection')\n",
        "\n",
        "if topicc_model =='yes':\n",
        "  #TOPIC MODEL\n",
        "  import pandas as pd\n",
        "  import re\n",
        "  from gensim import corpora, models, similarities\n",
        "  import nltk\n",
        "  from nltk.corpus import stopwords\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import sys\n",
        "  # !{sys.executable} -m spacy download en\n",
        "  import re, numpy as np, pandas as pd\n",
        "  from pprint import pprint\n",
        "\n",
        "  import gensim, spacy, logging, warnings\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  import gensim.corpora as corpora\n",
        "  from gensim.utils import  simple_preprocess\n",
        "  from gensim.models import CoherenceModel\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words=['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come']\n",
        "\n",
        "  warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "  logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "  red_it = pd.DataFrame()\n",
        "  red_it['personal_stories'] = df_reviews['reviews']\n",
        "  red_it = pd.DataFrame(red_it['personal_stories'])\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  import gensim\n",
        "  from gensim.utils import simple_preprocess\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(['from', 'subject', 're', 'edu', 'use','www','https','com','fags','string','sleep','apnea','cpap','co','machine','get','getting'])\n",
        "  def sent_to_words(sentences):\n",
        "      for sentence in sentences:\n",
        "          yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "  def remove_stopwords(texts):\n",
        "      return [[word for word in simple_preprocess(str(doc)) \n",
        "                if word not in stop_words] for doc in texts]\n",
        "  data = red_it.personal_stories.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  data_words = remove_stopwords(data_words)\n",
        "\n",
        "  import gensim.corpora as corpora\n",
        "  id2word = corpora.Dictionary(data_words)\n",
        "  texts = data_words\n",
        "  corpus = [id2word.doc2bow(text) for text in texts]\n",
        "  from pprint import pprint\n",
        "  lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                          id2word=id2word,\n",
        "                                          num_topics=xcv)\n",
        "  pprint(lda_model.print_topics())\n",
        "  doc_lda = lda_model[corpus]\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "  def sent_to_words(sentences):\n",
        "      for sent in sentences:\n",
        "          sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "          yield(sent)\n",
        "\n",
        "  data = red_it.personal_stories.values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "  print(data_words[:1])\n",
        "\n",
        "\n",
        "  bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "\n",
        "  def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "      \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
        "      texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "      texts = [bigram_mod[doc] for doc in texts]\n",
        "      texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      texts_out = []\n",
        "      for sent in texts:\n",
        "          doc = nlp(\" \".join(sent)) \n",
        "          texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "      texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "      return texts_out\n",
        "\n",
        "  data_ready = process_words(data_words)  \n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  id2word = corpora.Dictionary(data_ready)\n",
        "\n",
        "  corpus = [id2word.doc2bow(text) for text in data_ready]\n",
        "\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                              id2word=id2word,\n",
        "                                              num_topics=xcv, \n",
        "                                              random_state=100,\n",
        "                                              update_every=1,\n",
        "                                              chunksize=10,\n",
        "                                              passes=10,\n",
        "                                              alpha='symmetric',\n",
        "                                              iterations=100,\n",
        "                                              per_word_topics=True)\n",
        "\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "  def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
        "      sent_topics_df = pd.DataFrame()\n",
        "\n",
        "      for i, row_list in enumerate(ldamodel[corpus]):\n",
        "          row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
        "          row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "          for j, (topic_num, prop_topic) in enumerate(row):\n",
        "              if j == 0:\n",
        "                  wp = ldamodel.show_topic(topic_num)\n",
        "                  topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "              else:\n",
        "                  break\n",
        "      sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "      contents = pd.Series(texts)\n",
        "      sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "      return(sent_topics_df)\n",
        "\n",
        "\n",
        "  df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
        "\n",
        "  df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "  df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "  df_dominant_topic.head(10)\n",
        "\n",
        "\n",
        "\n",
        "  pd.options.display.max_colwidth = 100\n",
        "\n",
        "  sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "  sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "  for i, grp in sent_topics_outdf_grpd:\n",
        "      sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                                grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
        "                                              axis=0)\n",
        "\n",
        "  sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
        "\n",
        "  sent_topics_sorteddf_mallet.head(10)\n",
        "\n",
        "  books_read = sent_topics_sorteddf_mallet\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  from matplotlib import pyplot as plt\n",
        "  from wordcloud import WordCloud, STOPWORDS\n",
        "  import matplotlib.colors as mcolors\n",
        "\n",
        "  cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
        "\n",
        "  cloud = WordCloud(stopwords=stop_words,\n",
        "                    background_color='white',\n",
        "                    width=2500,\n",
        "                    height=1800,\n",
        "                    max_words=20,\n",
        "                    colormap='tab10',\n",
        "                    color_func=lambda *args, **kwargs: cols[i],\n",
        "                    prefer_horizontal=1.0)\n",
        "\n",
        "  topics = lda_model.show_topics(formatted=False)\n",
        "\n",
        "  fig, axes = plt.subplots(4, 4, figsize=(20,20), sharex=True, sharey=True)\n",
        "  try:\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "      fig.add_subplot(ax)\n",
        "      topic_words = dict(topics[i][1])\n",
        "      cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
        "      plt.gca().imshow(cloud)\n",
        "      plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
        "      plt.gca().axis('off')\n",
        "  except:\n",
        "      dffd = 1\n",
        "\n",
        "  try:\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.axis('off')\n",
        "    plt.margins(x=0, y=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "  except:\n",
        "    dffd = 1\n",
        "\n",
        "  #---------------------------------------------------------------------------------\n",
        "\n",
        "  from collections import Counter\n",
        "  topics = lda_model.show_topics(formatted=False)\n",
        "  data_flat = [w for w_list in data_ready for w in w_list]\n",
        "  counter = Counter(data_flat)\n",
        "\n",
        "  out = []\n",
        "  for i, topic in topics:\n",
        "      for word, weight in topic:\n",
        "          out.append([word, i , weight, counter[word]])\n",
        "\n",
        "  df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
        "\n",
        "  fig, axes = plt.subplots(4, 4, figsize=(20,20), sharey=True, dpi=160)\n",
        "  cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
        "  try:\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
        "        ax_twin = ax.twinx()\n",
        "        ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
        "        ax.set_ylabel('Word Count', color=cols[i])\n",
        "        ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
        "        ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
        "        ax.tick_params(axis='y', left=False)\n",
        "        ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
        "        ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
        "\n",
        "    fig.tight_layout(w_pad=2)    \n",
        "    fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)   \n",
        "    plt.show()\n",
        "  except:\n",
        "    fwf = 1\n",
        "else:\n",
        "  print('no topic model')\n",
        "\n",
        "df_reviews\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eE7QihtP0jK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t89sY2jU0jNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xutuMccn0jQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scrapyard"
      ],
      "metadata": {
        "id": "C-TdliCw0jUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "hot_topics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}