{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Really_Hot_Prods.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:** need to download csv, copy/change path and create df in step 1. change time.sleep() intervals to slow down/speed up process. Change the user agen in 'headers' to your user agent (search 'my user agent' in chrome). \n",
        "\n",
        "Be careful not to exceed Amazon's request rate limit! The first scrape takes about 30 mins at time.sleep(random.randint(1,4) and I the actualy product/price/review scrape can take up to an hour!"
      ],
      "metadata": {
        "id": "16fNQTpIKeTl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nv50SJJhia01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e331ee61-3543-4b48-efb1-4b5817f0e031"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     second_arm  third_arm\n",
              "0             1          1\n",
              "1             1          2\n",
              "2             1          3\n",
              "3             1          4\n",
              "4             1          5\n",
              "..          ...        ...\n",
              "549          36         11\n",
              "550          36         12\n",
              "551          36         13\n",
              "552          36         14\n",
              "553          36         15\n",
              "\n",
              "[554 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57c0b9b8-9fb2-4022-bbc0-3ddedc1ca209\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>second_arm</th>\n",
              "      <th>third_arm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>36</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>36</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>36</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>36</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>554 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57c0b9b8-9fb2-4022-bbc0-3ddedc1ca209')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57c0b9b8-9fb2-4022-bbc0-3ddedc1ca209 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57c0b9b8-9fb2-4022-bbc0-3ddedc1ca209');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "#download the spreadsheet that directs the bot at 'https://docs.google.com/spreadsheets/d/1j1zp8yHJbXMwSe58bW38MODuD9wOYDWfPhklsKTqjqI/edit?usp=sharing', its pretty straightforward\n",
        "df = pd.read_csv('/content/Arms_AMZN - Sheet1 (1).csv')\n",
        "\n",
        "#get page url's for all individual categories (note: URL IS VARIABLE, you should be able to use best sellers or another ranked AMZ category)\n",
        "cat_names1 = {'names':[]}\n",
        "cat_names2 = {'names':[]}\n",
        "cat_names3 = {'names':[]}\n",
        "for x in range(len(df)):\n",
        "  try:\n",
        "    num2 = df['second_arm'][x]\n",
        "    num2 = int(num2) - 1\n",
        "  except:\n",
        "    print('num2 problem')\n",
        "  try:\n",
        "    num3 = df['third_arm'][x]\n",
        "    num3 = int(num3) - 1\n",
        "  except:\n",
        "    print('num3 problem')\n",
        "  try:\n",
        "    url = 'https://www.amazon.com/gp/new-releases/'\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
        "    cat_names = {'names':[]}\n",
        "    html = requests.get(url,headers = headers).text\n",
        "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-small__nleKL\"}):\n",
        "            cat_names['names'].append(tag.findNext(\"a\"))\n",
        "  except:\n",
        "    print('arm 1 error')\n",
        "  try:\n",
        "    url = 'https://www.amazon.com'+ str(cat_names['names'][num2]).split('\"')[1]\n",
        "    html = requests.get(url,headers = headers).text\n",
        "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"_p13n-zg-nav-tree-all_style_zg-browse-group__88fbz\"}):\n",
        "            cat_names1['names'].append(tag.findAll(\"a\"))\n",
        "  except:\n",
        "      print('arm 2 error')\n",
        "  try:\n",
        "    cat_names1['names']\n",
        "    url2 = 'https://www.amazon.com'+ str(cat_names1['names'][num3]).split('\"')[1]\n",
        "    html = requests.get(url2,headers = headers).text\n",
        "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8\"}):\n",
        "            cat_names2['names'].append(tag.findAll(\"a\"))\n",
        "  except:\n",
        "    print('arm 3 error')\n",
        "  time.sleep(random.randint(1, 4))\n",
        "\n",
        "#collect all collected links, droping any duplicates\n",
        "all1 = {'link':[],'name':[]}\n",
        "for x in range(len(cat_names1['names'])):\n",
        "  for xx in range(len(cat_names1['names'][x])):\n",
        "    all1['link'].append('https://www.amazon.com'+str(cat_names1['names'][x][xx]).split('\"')[1])\n",
        "    all1['name'].append(str(cat_names1['names'][x][xx]).split('\"')[2])\n",
        "print('length of secondary links collected'+str(len(pd.DataFrame(all1['link']).drop_duplicates())))\n",
        "print('length of secondary names collected'+str(len(pd.DataFrame(all1['names']).drop_duplicates())))\n",
        "\n",
        "all2 = {'link':[],'name':[]}\n",
        "for x in range(len(cat_names2['names'])):\n",
        "  for xx in range(len(cat_names2['names'][x])):\n",
        "    all2['link'].append('https://www.amazon.com'+str(cat_names2['names'][x][xx]).split('\"')[1])\n",
        "    all2['name'].append(str(cat_names2['names'][x][xx]).split('\"')[2])\n",
        "print('length of primary links collected'+str(len(pd.DataFrame(all2['link']).drop_duplicates())))\n",
        "print('length of primary names collected'+str(len(pd.DataFrame(all2['name']).drop_duplicates())))\n",
        "\n",
        "#mor orgnaization... getting top then bottom level urls\n",
        "aaa = pd.DataFrame()\n",
        "aaa['link'] = pd.DataFrame(all2['link']).drop_duplicates()[0]\n",
        "aaa['name'] = pd.DataFrame(all2['name']).drop_duplicates()[0]\n",
        "aa = pd.DataFrame()\n",
        "aa[['link','name']] = pd.merge(pd.DataFrame(all1['link']).reset_index(),pd.DataFrame(all1['name']).reset_index(), on = 'index').drop(columns = 'index').drop_duplicates()\n",
        "aa = aa.append(aaa)\n",
        "aa = aa.reset_index()\n",
        "aa = aa.sort_values('index').drop(columns = 'index')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scraping the first + second image, rating + # of ratings, and price to observe day to day patterns\n",
        "cat_names = {'imageLink':[],'imageLink1':[],'brand':[],'rating':[],'price':[]}\n",
        "cat_names1 = {'imageLink':[],'imageLink1':[],'brand':[],'rating':[],'price':[]}\n",
        "\n",
        "for x in range(len(aa['names'])):\n",
        "  try:\n",
        "    url = aa['link'][x]\n",
        "    url2 = str(aa['link'][x]).split('ref=')[0]+'ref='+str(aa['link'][x]).split('ref=')[1].split(\"_1\")[0]+'_2?ie=UTF8&pg=2'\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}\n",
        "    html = requests.get(url,headers = headers).text\n",
        "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"a-section a-spacing-mini _p13n-zg-list-grid-desktop_maskStyle_noop__3Xbw5\"}):\n",
        "            tt = {'imageLink':[]}\n",
        "            tt['imageLink'].append(tag.findAll(\"img\"))\n",
        "            for x in range(len(tt['imageLink'])):\n",
        "              cat_names['brand'].append(str(tt['imageLink'][x]).split('\"')[1])\n",
        "              cat_names['imageLink'].append(str(tt['imageLink'][x]).split('\"')[5])\n",
        "              cat_names['imageLink1'].append(str(tt['imageLink'][x]).split('\"')[7])\n",
        "            \n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"a-icon-row\"}):\n",
        "            cat_names['rating'].append(tag.findNext(\"span\").text)\n",
        "    for tag in soup.findAll(\"span\", {\"class\": \"a-size-base a-color-price\"}):\n",
        "            cat_names['price'].append(tag.findNext(\"span\",{\"class\":\"_p13n-zg-list-grid-desktop_price_p13n-sc-price__3mJ9Z\"}).text)\n",
        "  except:\n",
        "    print('first 50, error with link: '+ str(url))\n",
        "\n",
        "  time.sleep(random.randint(1,2))\n",
        "#-------------------------------------------------------------------------------------------------------------\n",
        "  try:\n",
        "    html1 = requests.get(url2,headers = headers).text\n",
        "    soup1 = bs4.BeautifulSoup(html1, \"html.parser\")\n",
        "    for tag in soup1.findAll(\"div\", {\"class\": \"a-section a-spacing-mini _p13n-zg-list-grid-desktop_maskStyle_noop__3Xbw5\"}):\n",
        "            tt = {'imageLink':[]}\n",
        "            tt['imageLink'].append(tag.findAll(\"img\"))\n",
        "            for x in range(len(tt['imageLink'])):\n",
        "              cat_names1['brand'].append(str(tt['imageLink'][x]).split('\"')[1])\n",
        "              cat_names1['imageLink'].append(str(tt['imageLink'][x]).split('\"')[5])\n",
        "              cat_names1['imageLink1'].append(str(tt['imageLink'][x]).split('\"')[7])\n",
        "            \n",
        "    for tag in soup.findAll(\"div\", {\"class\": \"a-icon-row\"}):\n",
        "            cat_names1['rating'].append(tag.findNext(\"span\").text)\n",
        "    for tag in soup.findAll(\"span\", {\"class\": \"a-size-base a-color-price\"}):\n",
        "            cat_names1['price'].append(tag.findNext(\"span\",{\"class\":\"_p13n-zg-list-grid-desktop_price_p13n-sc-price__3mJ9Z\"}).text)\n",
        "\n",
        "    print(len(cat_names1['imageLink']))\n",
        "    print(len(cat_names1['imageLink1']))\n",
        "    print(len(cat_names1['brand']))\n",
        "    print(len(cat_names1['rating']))\n",
        "    print(len(cat_names1['price']))\n",
        "\n",
        "  except:\n",
        "    print('second 50, error with link: '+ url2)\n",
        "  \n",
        "  time.sleep(random.randint(1,2))\n"
      ],
      "metadata": {
        "id": "88nbCrow6MFU"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#next steps: delete duplicate products + organize data, note: selenium needed to access 40/100 products per category --> bs4 doesnt scroll scrape and my comp doesn't work with selenium!"
      ],
      "metadata": {
        "id": "Xxea8mQUKHU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a-pWqbxQKHXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V1q3ZP-WKHav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}